{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbebc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1) Модель: простая RNN (LSTM) с выходом-эмбеддингом размерности D\n",
    "class SphericalRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding_dim, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden_size, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len, input_size]\n",
    "        _, (h_n, _) = self.lstm(x)           # h_n: [n_layers, batch, hidden_size]\n",
    "        h_last      = h_n[-1]                # [batch, hidden_size]\n",
    "        z            = self.fc(h_last)       # [batch, embedding_dim]\n",
    "        z_sphere     = nn.functional.normalize(z, p=2, dim=1)  # L2-нормализация\n",
    "        return z_sphere                       # все векторы на S^{D-1}\n",
    "\n",
    "# 2) Функция тренировки с мини-батч кластеризацией  \n",
    "def train_epoch(model, dataloader, optimizer, device, n_clusters=10):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        x = batch.to(device)                # [batch, seq_len, input_size]\n",
    "        z = model(x)                        # [batch, D] — на сфере\n",
    "\n",
    "        # 2.1) Кластеризуем эмбеддинги (mini-batch k-means на сфере)\n",
    "        #      Используем косинусное расстояние = 1 - dot(z_i, center_j)\n",
    "        #      sklearn.KMeans по умолчанию — Евклид, но на L2-нормированных данных\n",
    "        #      Евклидова метрика эквивалентна косинусу.\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "        labels = kmeans.fit_predict(z.detach().cpu().numpy())\n",
    "        centers = torch.tensor(kmeans.cluster_centers_, device=device)\n",
    "        centers = nn.functional.normalize(centers, p=2, dim=1)  # центры тоже на сфере\n",
    "\n",
    "        # 2.2) Loss: среднее косинус-расстояние до своего центра\n",
    "        #      косинус-расстояние = 1 - dot(z, center)\n",
    "        z_expand      = z.unsqueeze(1)                   # [batch, 1, D]\n",
    "        centers_expand = centers.unsqueeze(0)            # [1, n_clusters, D]\n",
    "        # dot: [batch, n_clusters]\n",
    "        cos_sim      = torch.bmm(z_expand, centers_expand.transpose(1,2)).squeeze(1)\n",
    "        # собираем по меткам\n",
    "        chosen_sim   = cos_sim[torch.arange(z.size(0)), labels]\n",
    "        loss         = torch.mean(1.0 - chosen_sim)      # хотим максимум сходства → минимум (1 - cos)\n",
    "\n",
    "        # 2.3) Шаг оптимизации\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * z.size(0)\n",
    "\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# 3) Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    # Параметры\n",
    "    input_size   = 5       # размерность вашего признакового вектора на шаге time-series\n",
    "    hidden_size  = 64\n",
    "    embedding_dim= 16      # размерность сферы S^{15}\n",
    "    n_clusters   = 8\n",
    "    lr           = 1e-3\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model  = SphericalRNN(input_size, hidden_size, embedding_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Датасет: ваш DataLoader для time-series\n",
    "    # должен отдавать тензор shape=[batch, seq_len, input_size]\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    # пример: случайные данные\n",
    "    dummy = torch.randn(1000, 50, input_size)\n",
    "    loader = DataLoader(TensorDataset(dummy), batch_size=32, shuffle=True)\n",
    "\n",
    "    # Тренировка\n",
    "    for epoch in range(1, 11):\n",
    "        avg_loss = train_epoch(model, loader, optimizer, device, n_clusters)\n",
    "        print(f\"Epoch {epoch:02d}, Loss = {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
