{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('../src') \n",
    "from model import SphericalRNN\n",
    "from trainer import train_epoch\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59540/59540 [00:07<00:00, 7632.97it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_features(path=\"../data/xrp_futures.csv\", n_timesteps=50):\n",
    "    df = pd.read_csv(path)\n",
    "    x = (df.close.values - df.open.values) / df.open.values\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    samples = []\n",
    "    prices = []\n",
    "    features = []\n",
    "    for i in tqdm(range(n_timesteps, len(df))):\n",
    "        samples.append(np.array([x[i - n_timesteps : i]]).reshape(-1, 1))\n",
    "        Open, High, Low, Close = df.iloc[i - n_timesteps : i, 2:6].values.T\n",
    "        # total_delta, volatility_per_step, volatility_total\n",
    "        features.append(\n",
    "            [\n",
    "                (Close[-1] - Open[0]) / Open[0],\n",
    "                np.mean(((High - Low) / Open)),\n",
    "                Close.std() / Open[0],\n",
    "            ]\n",
    "        )\n",
    "    return torch.tensor(samples), np.array(features), prices\n",
    "\n",
    "\n",
    "x_train, features, prices = get_features(n_timesteps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    # 1. Python built-in random\n",
    "    random.seed(seed)\n",
    "\n",
    "    # 2. NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 3. Torch (CPU)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # 4. Torch (all GPUs, if you’re using CUDA)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # 5. cuDNN – for reproducibility (but may slow things down)\n",
    "    #    * deterministic = True makes operations deterministic\n",
    "    #    * benchmark = False stops cuDNN from trying to find\n",
    "    #      the fastest algorithm (which can introduce randomness)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # 6. (Optional) Force a fixed hash seed for Python >=3.3\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "# Usage\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SphericalRNN(\n",
       "  (lstm): LSTM(1, 6, batch_first=True)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "n_clusters = 3\n",
    "dim_hidden = 16\n",
    "n_layers = 0\n",
    "model = (\n",
    "    SphericalRNN(\n",
    "        input_size=1,\n",
    "        hidden_size=6,\n",
    "        embedding_dim=4,\n",
    "        n_layers=1,\n",
    "        mlp_hidden_dims=[dim_hidden for i in range(n_layers)],\n",
    "    )\n",
    "    .to(dtype=torch.float64, device=device)\n",
    "    .eval(),\n",
    ")[0]\n",
    "torch.manual_seed(42)\n",
    "lr = 1e-4\n",
    "n_epochs = 3\n",
    "batch_size = 32\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "for i in range(n_epochs):\n",
    "    train_epoch(\n",
    "        model=model,\n",
    "        x_train=x_train,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        n_clusters=n_clusters,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "z = model(x_train.to(device=device)).cpu()\n",
    "labels = kmeans.fit_predict(z.detach().cpu().numpy())\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_delta</th>\n",
       "      <th>volatility_per_step</th>\n",
       "      <th>volatility_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.011827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000447</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.014264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026330</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>0.021689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_delta  volatility_per_step  volatility_total\n",
       "0     0.005254             0.007680          0.011827\n",
       "1    -0.000447             0.008703          0.014264\n",
       "2     0.026330             0.011764          0.021689"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_data = []\n",
    "for i in range(n_clusters):\n",
    "    res_data.append(np.mean(features[labels == i], axis=0))\n",
    "\n",
    "pd.DataFrame(\n",
    "    data=res_data, columns=[\"total_delta\", \"volatility_per_step\", \"volatility_total\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear unused memory from Python and CUDA\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
